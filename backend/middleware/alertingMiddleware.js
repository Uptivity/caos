/**
 * Alerting and Error Tracking Middleware
 * Basic alerting system with configurable thresholds and notification channels
 */

const { logger } = require('../utils/logger');
const { performanceMonitor } = require('./performanceMiddleware');
const { metricsCollector } = require('./metricsMiddleware');

class AlertingSystem {
    constructor() {
        this.alerts = new Map();
        this.alertHistory = [];
        this.maxHistoryEntries = 500;

        // Configuration from environment variables
        this.config = {
            // Error rate thresholds
            errorRateThresholdWarning: parseFloat(process.env.ERROR_RATE_WARNING_THRESHOLD) || 5.0, // %
            errorRateThresholdCritical: parseFloat(process.env.ERROR_RATE_CRITICAL_THRESHOLD) || 10.0, // %

            // Response time thresholds
            responseTimeThresholdWarning: parseInt(process.env.RESPONSE_TIME_WARNING_THRESHOLD) || 1000, // ms
            responseTimeThresholdCritical: parseInt(process.env.RESPONSE_TIME_CRITICAL_THRESHOLD) || 2000, // ms

            // Database thresholds
            dbConnectionThresholdWarning: parseInt(process.env.DB_CONNECTION_WARNING_THRESHOLD) || 80, // %
            dbConnectionThresholdCritical: parseInt(process.env.DB_CONNECTION_CRITICAL_THRESHOLD) || 90, // %

            // Memory thresholds
            memoryThresholdWarning: parseInt(process.env.MEMORY_WARNING_THRESHOLD) || 80, // %
            memoryThresholdCritical: parseInt(process.env.MEMORY_CRITICAL_THRESHOLD) || 90, // %

            // CPU thresholds
            cpuThresholdWarning: parseInt(process.env.CPU_WARNING_THRESHOLD) || 75, // %
            cpuThresholdCritical: parseInt(process.env.CPU_CRITICAL_THRESHOLD) || 90, // %

            // Alert suppression (prevent spam)
            alertSuppressionWindow: parseInt(process.env.ALERT_SUPPRESSION_WINDOW) || 300000, // 5 minutes

            // Check intervals
            checkInterval: parseInt(process.env.ALERT_CHECK_INTERVAL) || 60000, // 1 minute

            // Notification channels
            enableEmailAlerts: process.env.ENABLE_EMAIL_ALERTS === 'true',
            enableWebhookAlerts: process.env.ENABLE_WEBHOOK_ALERTS === 'true',
            alertWebhookUrl: process.env.ALERT_WEBHOOK_URL,
            alertEmailFrom: process.env.ALERT_EMAIL_FROM || 'alerts@caos-crm.com',
            alertEmailTo: process.env.ALERT_EMAIL_TO?.split(',') || [],

            // Slack integration
            enableSlackAlerts: process.env.ENABLE_SLACK_ALERTS === 'true',
            slackWebhookUrl: process.env.SLACK_WEBHOOK_URL,
            slackChannel: process.env.SLACK_CHANNEL || '#alerts'
        };\n\n        this.alertTypes = {\n            ERROR_RATE: 'error_rate',\n            RESPONSE_TIME: 'response_time',\n            DATABASE: 'database',\n            MEMORY: 'memory',\n            CPU: 'cpu',\n            DISK: 'disk',\n            SECURITY: 'security',\n            BUSINESS: 'business'\n        };\n\n        this.severityLevels = {\n            INFO: 'info',\n            WARNING: 'warning',\n            CRITICAL: 'critical'\n        };\n\n        // Start monitoring\n        this.startMonitoring();\n\n        logger.info('Alerting system initialized', {\n            thresholds: {\n                errorRate: `${this.config.errorRateThresholdWarning}%/${this.config.errorRateThresholdCritical}%`,\n                responseTime: `${this.config.responseTimeThresholdWarning}ms/${this.config.responseTimeThresholdCritical}ms`,\n                memory: `${this.config.memoryThresholdWarning}%/${this.config.memoryThresholdCritical}%`\n            },\n            channels: {\n                email: this.config.enableEmailAlerts,\n                webhook: this.config.enableWebhookAlerts,\n                slack: this.config.enableSlackAlerts\n            }\n        });\n    }\n\n    /**\n     * Start monitoring and alerting\n     */\n    startMonitoring() {\n        setInterval(() => {\n            this.checkSystemHealth();\n        }, this.config.checkInterval);\n\n        logger.info('System monitoring started', {\n            interval: `${this.config.checkInterval}ms`\n        });\n    }\n\n    /**\n     * Check overall system health and trigger alerts\n     */\n    async checkSystemHealth() {\n        try {\n            // Check error rates\n            await this.checkErrorRates();\n\n            // Check response times\n            await this.checkResponseTimes();\n\n            // Check database health\n            await this.checkDatabaseHealth();\n\n            // Check system resources\n            await this.checkSystemResources();\n\n        } catch (error) {\n            logger.error('System health check failed', {\n                error: error.message,\n                stack: error.stack\n            });\n        }\n    }\n\n    /**\n     * Check API error rates\n     */\n    async checkErrorRates() {\n        const coreWebVitals = performanceMonitor.getCoreWebVitals();\n        const errorRate = parseFloat(coreWebVitals.errorRate);\n\n        if (errorRate >= this.config.errorRateThresholdCritical) {\n            await this.triggerAlert(this.alertTypes.ERROR_RATE, this.severityLevels.CRITICAL, {\n                message: `Critical error rate detected: ${errorRate}%`,\n                threshold: `${this.config.errorRateThresholdCritical}%`,\n                currentValue: `${errorRate}%`,\n                requestVolume: coreWebVitals.requestVolume\n            });\n        } else if (errorRate >= this.config.errorRateThresholdWarning) {\n            await this.triggerAlert(this.alertTypes.ERROR_RATE, this.severityLevels.WARNING, {\n                message: `High error rate detected: ${errorRate}%`,\n                threshold: `${this.config.errorRateThresholdWarning}%`,\n                currentValue: `${errorRate}%`,\n                requestVolume: coreWebVitals.requestVolume\n            });\n        }\n    }\n\n    /**\n     * Check API response times\n     */\n    async checkResponseTimes() {\n        const coreWebVitals = performanceMonitor.getCoreWebVitals();\n        const avgResponseTime = parseFloat(coreWebVitals.averageResponseTime);\n\n        if (avgResponseTime >= this.config.responseTimeThresholdCritical) {\n            await this.triggerAlert(this.alertTypes.RESPONSE_TIME, this.severityLevels.CRITICAL, {\n                message: `Critical response time detected: ${avgResponseTime.toFixed(0)}ms`,\n                threshold: `${this.config.responseTimeThresholdCritical}ms`,\n                currentValue: `${avgResponseTime.toFixed(0)}ms`,\n                percentiles: coreWebVitals.percentiles\n            });\n        } else if (avgResponseTime >= this.config.responseTimeThresholdWarning) {\n            await this.triggerAlert(this.alertTypes.RESPONSE_TIME, this.severityLevels.WARNING, {\n                message: `Slow response time detected: ${avgResponseTime.toFixed(0)}ms`,\n                threshold: `${this.config.responseTimeThresholdWarning}ms`,\n                currentValue: `${avgResponseTime.toFixed(0)}ms`,\n                percentiles: coreWebVitals.percentiles\n            });\n        }\n    }\n\n    /**\n     * Check database health\n     */\n    async checkDatabaseHealth() {\n        const database = require('../config/database');\n        \n        try {\n            const dbHealth = await database.getHealthStatus();\n            const poolStats = database.getPoolStatus();\n            \n            if (!dbHealth.connected) {\n                await this.triggerAlert(this.alertTypes.DATABASE, this.severityLevels.CRITICAL, {\n                    message: 'Database connection lost',\n                    status: dbHealth.status,\n                    error: dbHealth.error\n                });\n                return;\n            }\n\n            // Check connection pool utilization\n            const poolUtilization = poolStats.totalConnections > 0 \n                ? (poolStats.usedConnections / poolStats.totalConnections) * 100\n                : 0;\n\n            if (poolUtilization >= this.config.dbConnectionThresholdCritical) {\n                await this.triggerAlert(this.alertTypes.DATABASE, this.severityLevels.CRITICAL, {\n                    message: `Critical database connection pool usage: ${poolUtilization.toFixed(1)}%`,\n                    threshold: `${this.config.dbConnectionThresholdCritical}%`,\n                    currentValue: `${poolUtilization.toFixed(1)}%`,\n                    poolStats\n                });\n            } else if (poolUtilization >= this.config.dbConnectionThresholdWarning) {\n                await this.triggerAlert(this.alertTypes.DATABASE, this.severityLevels.WARNING, {\n                    message: `High database connection pool usage: ${poolUtilization.toFixed(1)}%`,\n                    threshold: `${this.config.dbConnectionThresholdWarning}%`,\n                    currentValue: `${poolUtilization.toFixed(1)}%`,\n                    poolStats\n                });\n            }\n\n            // Check database response time\n            const responseTime = dbHealth.responseTime ? parseInt(dbHealth.responseTime) : 0;\n            if (responseTime > 500) {\n                await this.triggerAlert(this.alertTypes.DATABASE, this.severityLevels.WARNING, {\n                    message: `Slow database response time: ${responseTime}ms`,\n                    threshold: '500ms',\n                    currentValue: `${responseTime}ms`\n                });\n            }\n\n        } catch (error) {\n            await this.triggerAlert(this.alertTypes.DATABASE, this.severityLevels.CRITICAL, {\n                message: 'Database health check failed',\n                error: error.message\n            });\n        }\n    }\n\n    /**\n     * Check system resources (memory, CPU)\n     */\n    async checkSystemResources() {\n        const os = require('os');\n        \n        // Memory check\n        const totalMemory = os.totalmem();\n        const freeMemory = os.freemem();\n        const memoryUsage = ((totalMemory - freeMemory) / totalMemory) * 100;\n\n        if (memoryUsage >= this.config.memoryThresholdCritical) {\n            await this.triggerAlert(this.alertTypes.MEMORY, this.severityLevels.CRITICAL, {\n                message: `Critical memory usage: ${memoryUsage.toFixed(1)}%`,\n                threshold: `${this.config.memoryThresholdCritical}%`,\n                currentValue: `${memoryUsage.toFixed(1)}%`,\n                totalMemory: `${(totalMemory / 1024 / 1024 / 1024).toFixed(2)}GB`,\n                freeMemory: `${(freeMemory / 1024 / 1024 / 1024).toFixed(2)}GB`\n            });\n        } else if (memoryUsage >= this.config.memoryThresholdWarning) {\n            await this.triggerAlert(this.alertTypes.MEMORY, this.severityLevels.WARNING, {\n                message: `High memory usage: ${memoryUsage.toFixed(1)}%`,\n                threshold: `${this.config.memoryThresholdWarning}%`,\n                currentValue: `${memoryUsage.toFixed(1)}%`,\n                totalMemory: `${(totalMemory / 1024 / 1024 / 1024).toFixed(2)}GB`,\n                freeMemory: `${(freeMemory / 1024 / 1024 / 1024).toFixed(2)}GB`\n            });\n        }\n\n        // CPU check (simplified)\n        const loadAvg = os.loadavg();\n        const numCPUs = os.cpus().length;\n        const cpuUsage = (loadAvg[0] / numCPUs) * 100;\n\n        if (cpuUsage >= this.config.cpuThresholdCritical) {\n            await this.triggerAlert(this.alertTypes.CPU, this.severityLevels.CRITICAL, {\n                message: `Critical CPU usage: ${cpuUsage.toFixed(1)}%`,\n                threshold: `${this.config.cpuThresholdCritical}%`,\n                currentValue: `${cpuUsage.toFixed(1)}%`,\n                loadAverage: loadAvg[0].toFixed(2),\n                cores: numCPUs\n            });\n        } else if (cpuUsage >= this.config.cpuThresholdWarning) {\n            await this.triggerAlert(this.alertTypes.CPU, this.severityLevels.WARNING, {\n                message: `High CPU usage: ${cpuUsage.toFixed(1)}%`,\n                threshold: `${this.config.cpuThresholdWarning}%`,\n                currentValue: `${cpuUsage.toFixed(1)}%`,\n                loadAverage: loadAvg[0].toFixed(2),\n                cores: numCPUs\n            });\n        }\n    }\n\n    /**\n     * Trigger an alert\n     */\n    async triggerAlert(type, severity, details) {\n        const alertKey = `${type}_${severity}`;\n        const now = Date.now();\n        \n        // Check if alert should be suppressed\n        const lastAlert = this.alerts.get(alertKey);\n        if (lastAlert && (now - lastAlert.timestamp) < this.config.alertSuppressionWindow) {\n            logger.debug('Alert suppressed due to suppression window', {\n                type,\n                severity,\n                suppressionWindow: `${this.config.alertSuppressionWindow}ms`\n            });\n            return;\n        }\n\n        const alert = {\n            id: this.generateAlertId(),\n            type,\n            severity,\n            timestamp: now,\n            message: details.message,\n            details,\n            resolved: false,\n            environment: process.env.NODE_ENV || 'development'\n        };\n\n        // Store alert\n        this.alerts.set(alertKey, alert);\n        this.addToHistory(alert);\n\n        // Log alert\n        logger.warn('Alert triggered', alert);\n\n        // Send notifications\n        await this.sendNotifications(alert);\n\n        return alert;\n    }\n\n    /**\n     * Generate unique alert ID\n     */\n    generateAlertId() {\n        return `alert_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;\n    }\n\n    /**\n     * Send alert notifications through configured channels\n     */\n    async sendNotifications(alert) {\n        const notifications = [];\n\n        // Email notifications\n        if (this.config.enableEmailAlerts && this.config.alertEmailTo.length > 0) {\n            notifications.push(this.sendEmailAlert(alert));\n        }\n\n        // Webhook notifications\n        if (this.config.enableWebhookAlerts && this.config.alertWebhookUrl) {\n            notifications.push(this.sendWebhookAlert(alert));\n        }\n\n        // Slack notifications\n        if (this.config.enableSlackAlerts && this.config.slackWebhookUrl) {\n            notifications.push(this.sendSlackAlert(alert));\n        }\n\n        // Wait for all notifications to complete\n        try {\n            await Promise.allSettled(notifications);\n        } catch (error) {\n            logger.error('Error sending alert notifications', {\n                alertId: alert.id,\n                error: error.message\n            });\n        }\n    }\n\n    /**\n     * Send email alert (basic implementation)\n     */\n    async sendEmailAlert(alert) {\n        try {\n            // In a real implementation, you would integrate with an email service\n            // like SendGrid, AWS SES, or SMTP\n            logger.info('Email alert would be sent', {\n                alertId: alert.id,\n                to: this.config.alertEmailTo,\n                subject: `[${alert.severity.toUpperCase()}] CAOS CRM Alert: ${alert.type}`,\n                message: alert.message\n            });\n        } catch (error) {\n            logger.error('Failed to send email alert', {\n                alertId: alert.id,\n                error: error.message\n            });\n        }\n    }\n\n    /**\n     * Send webhook alert\n     */\n    async sendWebhookAlert(alert) {\n        try {\n            // In a real implementation, you would make HTTP request to webhook URL\n            logger.info('Webhook alert would be sent', {\n                alertId: alert.id,\n                url: this.config.alertWebhookUrl,\n                payload: alert\n            });\n        } catch (error) {\n            logger.error('Failed to send webhook alert', {\n                alertId: alert.id,\n                error: error.message\n            });\n        }\n    }\n\n    /**\n     * Send Slack alert\n     */\n    async sendSlackAlert(alert) {\n        try {\n            const color = alert.severity === 'critical' ? 'danger' : 'warning';\n            const emoji = alert.severity === 'critical' ? '🚨' : '⚠️';\n            \n            const slackPayload = {\n                channel: this.config.slackChannel,\n                username: 'CAOS CRM Alerts',\n                icon_emoji: ':exclamation:',\n                attachments: [{\n                    color: color,\n                    title: `${emoji} ${alert.severity.toUpperCase()} Alert: ${alert.type}`,\n                    text: alert.message,\n                    fields: [\n                        {\n                            title: 'Environment',\n                            value: alert.environment,\n                            short: true\n                        },\n                        {\n                            title: 'Timestamp',\n                            value: new Date(alert.timestamp).toISOString(),\n                            short: true\n                        }\n                    ],\n                    footer: 'CAOS CRM Monitoring',\n                    ts: Math.floor(alert.timestamp / 1000)\n                }]\n            };\n\n            logger.info('Slack alert would be sent', {\n                alertId: alert.id,\n                channel: this.config.slackChannel,\n                payload: slackPayload\n            });\n        } catch (error) {\n            logger.error('Failed to send Slack alert', {\n                alertId: alert.id,\n                error: error.message\n            });\n        }\n    }\n\n    /**\n     * Add alert to history\n     */\n    addToHistory(alert) {\n        this.alertHistory.push(alert);\n        \n        // Keep only recent entries\n        if (this.alertHistory.length > this.maxHistoryEntries) {\n            this.alertHistory.shift();\n        }\n    }\n\n    /**\n     * Get current active alerts\n     */\n    getActiveAlerts() {\n        return Array.from(this.alerts.values()).filter(alert => !alert.resolved);\n    }\n\n    /**\n     * Get alert history\n     */\n    getAlertHistory(limit = 50) {\n        return this.alertHistory\n            .slice(-limit)\n            .sort((a, b) => b.timestamp - a.timestamp);\n    }\n\n    /**\n     * Get alert statistics\n     */\n    getAlertStatistics() {\n        const now = Date.now();\n        const last24h = now - (24 * 60 * 60 * 1000);\n        const last7d = now - (7 * 24 * 60 * 60 * 1000);\n        \n        const recent24h = this.alertHistory.filter(alert => alert.timestamp > last24h);\n        const recent7d = this.alertHistory.filter(alert => alert.timestamp > last7d);\n        \n        return {\n            active: this.getActiveAlerts().length,\n            total: this.alertHistory.length,\n            last24h: recent24h.length,\n            last7d: recent7d.length,\n            byType: this.groupAlertsByField(this.alertHistory, 'type'),\n            bySeverity: this.groupAlertsByField(this.alertHistory, 'severity'),\n            timestamp: new Date().toISOString()\n        };\n    }\n\n    /**\n     * Group alerts by field\n     */\n    groupAlertsByField(alerts, field) {\n        return alerts.reduce((groups, alert) => {\n            const key = alert[field];\n            groups[key] = (groups[key] || 0) + 1;\n            return groups;\n        }, {});\n    }\n\n    /**\n     * Resolve an alert\n     */\n    resolveAlert(alertId) {\n        for (const [key, alert] of this.alerts.entries()) {\n            if (alert.id === alertId) {\n                alert.resolved = true;\n                alert.resolvedAt = Date.now();\n                this.alerts.set(key, alert);\n                \n                logger.info('Alert resolved', { alertId });\n                return alert;\n            }\n        }\n        \n        return null;\n    }\n\n    /**\n     * Create Express endpoints for alert management\n     */\n    createAlertsEndpoint() {\n        const express = require('express');\n        const router = express.Router();\n\n        // Get active alerts\n        router.get('/active', (req, res) => {\n            res.json({\n                alerts: this.getActiveAlerts(),\n                count: this.getActiveAlerts().length,\n                timestamp: new Date().toISOString()\n            });\n        });\n\n        // Get alert history\n        router.get('/history', (req, res) => {\n            const limit = parseInt(req.query.limit) || 50;\n            res.json({\n                alerts: this.getAlertHistory(limit),\n                timestamp: new Date().toISOString()\n            });\n        });\n\n        // Get alert statistics\n        router.get('/stats', (req, res) => {\n            res.json(this.getAlertStatistics());\n        });\n\n        // Resolve alert\n        router.post('/:alertId/resolve', (req, res) => {\n            const alertId = req.params.alertId;\n            const resolvedAlert = this.resolveAlert(alertId);\n            \n            if (resolvedAlert) {\n                res.json({\n                    success: true,\n                    alert: resolvedAlert\n                });\n            } else {\n                res.status(404).json({\n                    error: 'Alert not found',\n                    alertId\n                });\n            }\n        });\n\n        return router;\n    }\n}\n\n// Create singleton instance\nconst alertingSystem = new AlertingSystem();\n\nmodule.exports = {\n    alertingSystem,\n    AlertingSystem\n};